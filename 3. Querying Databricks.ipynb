{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da1ee6dc-5394-4f03-85e9-f1eb06d7dab6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. Querying Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80620852-9e46-43fe-97f6-80939dbb4cae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This sample notebook will explain how you can read data from Databricks tables, and perform simple transformations with PySpark and SQL\n",
    "\n",
    "The instructions in this notebook assume that this is the first time a user has used Databricks before, and that they have not used this notebook in their environment before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19b70f44-5bfc-4921-b34f-55b3a3defcfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Preview Databricks Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "935ecb87-8d73-4697-b840-50adb4d6ebb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<br>\n",
    "If you want to preview your Databricks data and the schema using the UI, you can do this by clicking on the \"Catalog\" option on the left side bar, then selecting `atr_workshop` then `bronze_trips`\n",
    "\n",
    "![preview-data.png](./screenshots/preview-data.png)\n",
    "\n",
    "Once you click on that table, you will need to select an active cluster to be able to preview the data and see its schema. The area where you can select the cluster is located just below the name of the table. In this view you are also able to see the a description of the table (if it exists), the date the table was created, the date the table was last modified, the partitioned columns defined on the data, the number of underlying files the data is stored in and the size of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05e739f8-cda0-4968-b4f2-8aa769e0d461",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Query Databricks Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb6a222-4312-4523-acec-346d11d445a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./1. Configure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e702059e-c458-4f36-af10-da931ba885c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 'my_database' is defined as a Python variable, so we need to set that as well in a SQL context\n",
    "sql_command = f\"USE {my_database}\"\n",
    "spark.sql(sql_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09dd102e-e177-45e7-bb7f-8143a0e4949a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<br>\n",
    "Data can be queried in Databricks using SQL or Python. Since Databricks clusters run on Spark, you can use SparkSQL and PySpark to query data. Data in Azure Government Databricks is stored in a two level namespace; `database`.`table`. When querying data from these tables, you should specify both names in the namespace to ensure that you retrieve the correct data. To determine what data is available to query, you can click on the \"Catalog\" option on the left side bar to see the available databases and tables\n",
    "\n",
    "![catalog.png](./screenshots/catalog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba44f2d0-ef07-4360-a512-886141b0680d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Query Data using SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b363ed44-6a12-4060-a8ba-3590f5756a03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The below code show how you can query data in a Databricks table using standard SQL. Notice when you hover over the below cell, you will see a text that says \"SQL\" in the top right corner of the cell below. This is something that needs to be set in order to execute SQL code in a notebook. When you create a new cell, you can click on this box in the right to change it so that it is set to \"SQL\" if you want to write your code in SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc12f6bf-7bc9-4109-92c5-feef5e0f2baf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Simple Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77b86de2-c381-4610-b16f-17bbcd183195",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- select data from a table and only return a limited number of rows. this query will only return 100 records from the table\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  bronze_trips\n",
    "LIMIT 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8fcfe47-adc4-486e-8cdb-ad790cc0f3b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Time interval Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "622101bc-840b-47de-b3c2-3cffa6f854b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- select data from a table where a certain condition is met. this query will return all records that occured within the last 10 years\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  bronze_trips\n",
    "WHERE\n",
    "  tpep_pickup_datetime >= current_date() - INTERVAL 10 YEARS;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "972939ba-31f3-45d7-9222-1262c10475bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "When using SQL in a Databricks notebook, you can run multiple commands in a single cell as long as the commands are separated using a semi colon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a93aea5-a3fb-4a06-9140-7302348f5873",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Aggregate Grouping Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a07d7dc5-18ac-4bbc-9b11-21b0accdf877",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The following SQL query groups trips by their fare amount rounded down to the nearest $10, then counts how many trips are in each fare range.\n",
    "\n",
    "How it Works\n",
    "* For each trip:\n",
    "  * It divides the fare amount by 10, uses the FLOOR function to round down to the nearest whole number, then multiplies back by 10. This gets the nearest lower $10 multiple (for example, $23 becomes $20, $35 becomes $30).\n",
    "\n",
    "* It calls this result bin_fares (the fare \"bin\" for the trip).\n",
    "\n",
    "* It counts all trips in each bin_fares group.\n",
    "\n",
    "* It lists each fare bin and the number of trips in that bin, ordered from the lowest fare up.\n",
    "\n",
    "Why Use It\n",
    "* This makes a histogram of fares, showing how many trips fall into each $10 chunk.\n",
    "\n",
    "* The result is useful for quickly seeing fare patterns, like where most taxi fares fall on the price scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e101f4aa-4e86-436a-8aaf-3db852ca96e7",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1757519113905}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- select data from a table and create aggregations. this query will return an aggregated count of fares grouped into bins of 10\n",
    "SELECT \n",
    "  FLOOR(fare_amount / 10) * 10 AS bin_fares,\n",
    "  COUNT(*) AS count\n",
    "FROM bronze_trips\n",
    "GROUP BY bin_fares\n",
    "ORDER BY bin_fares\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b83d9e1-eb34-456a-9f35-4303f0387bd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Query Data using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "886c5124-5341-48db-81b9-4d554d98ac05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The below code shows how you can query data in a Databricks table using PySpark. Notice when you hover over the below cell, you will see a text that says \"Python\" in the top right corner of the cell below. This is something that needs to be set in order to execute PySpark code in a notebook. When you create a new cell, you can click on this box in the right to change it so that it is set to \"Python\" if you want to write your code in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "285aedfb-63c4-4892-ab47-2a7d99b18d3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Simple Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c58ed1e-4274-43c2-8db5-e80cb4e692d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#select data from a table and only return a limited number of rows. this query will only return 100 records from the table\n",
    "df = spark.table(\"bronze_trips\")\n",
    "display(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98b08818-8ce7-4944-8b4a-84bf7a943463",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Time Interval Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb42f7a0-a2ae-4c90-bb1e-2c8518b1e1e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# select data from a table where a certain condition is met. this query will return all records that occured within the last 10 years\n",
    "from pyspark.sql.functions import current_date, expr\n",
    "\n",
    "df = spark.table(\"bronze_trips\")\n",
    "display(\n",
    "    df.filter(df.tpep_pickup_datetime >= (current_date() - expr(\"INTERVAL 10 YEARS\")))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c4e36b2-bf37-41b0-9b7d-e5771a9308db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Aggregate Grouping Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e8d745a-cbca-4b22-bdf0-4869d981f07a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The following PySpark works as follows:\n",
    "\n",
    "* It adds a column called bin_fares to the data (df), rounding each fare down to the nearest $10 using the floor function (for example, $23 becomes $20).\n",
    "\n",
    "* It groups all trips by their bin_fares value.\n",
    "\n",
    "* It counts how many trips are in each group.\n",
    "\n",
    "* It sorts the result so all fare ranges appear in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "875d4511-c2ad-4069-9718-a9bfd6e6ef7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# select data from a table and create aggregations. this query will return an aggregated count of fares grouped into bins of 10\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = spark.table(\"bronze_trips\")\n",
    "\n",
    "display(\n",
    "    df.withColumn(\"bin_fares\", F.floor(F.col(\"fare_amount\") / 10) * 10)\n",
    "    .groupBy(\"bin_fares\")\n",
    "    .count()\n",
    "    .orderBy(\"bin_fares\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5832186c-a256-4a34-bed2-d39cb0654762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Additional Databricks Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cac93ce-d859-49cc-ad0c-b6d912a8ddc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "If you are interested in learning more about programming with SQL and PySpark in Databricks, please check out the following material online at https://customer-academy.databricks.com/learn. You can set up an account with our customer academy using your `.gov` email address\n",
    "\n",
    "- [Transform Data with Spark](https://customer-academy.databricks.com/learn/courses/1878/transform-data-with-spark)\n",
    "- [SQL Programming and Procedural Logic in Databricks](https://customer-academy.databricks.com/learn/course/4214/sql-programming-and-procedural-logic-in-databricks)\n",
    "- [Introduction to Python for Data Science and Data Engineering](https://customer-academy.databricks.com/learn/course/view/elearning/1211/introduction-to-python-for-data-science-and-data-engineering)\n",
    "- [Introduction to Apache Spark](https://customer-academy.databricks.com/learn/courses/3901/introduction-to-apache-spark)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7415273253318191,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "3. Querying Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}